<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IO模型 on JackTang&#39;s Blog</title>
    <link>https://jacktang816.github.io/categories/io%E6%A8%A1%E5%9E%8B/</link>
    <description>Recent content in IO模型 on JackTang&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 15 Jun 2019 20:14:35 +0800</lastBuildDate>
    
	<atom:link href="https://jacktang816.github.io/categories/io%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>linux 源码角度看 epoll</title>
      <link>https://jacktang816.github.io/post/epollsourceview/</link>
      <pubDate>Sat, 15 Jun 2019 20:14:35 +0800</pubDate>
      
      <guid>https://jacktang816.github.io/post/epollsourceview/</guid>
      <description>&lt;p&gt;对于较多数量的文件描述符的监听无论是select还是poll系统调用都显得捉襟见肘，正如前文&lt;a href=&#34;https://jacktang816.github.io/post/iomodel/&#34;&gt;Unix/Linux 中的五种 I/O 模型&lt;/a&gt;中对select/poll与epoll性能对比中所分析的，poll每次都需要将所有的文件描述符复制到内核，内核本身不会对这些文件描述符加以保存，这样的设计就导致了poll的效率的低下。而epoll则对此做了相应的改进，不是epoll_wait的时候才传入fd，而是通过epoll_ctl把所有fd传入内核，再一起&amp;rdquo;wait&amp;rdquo;，这就省掉了不必要的重复拷贝。其次，在 epoll_wait时，也不是把current轮流的加入fd对应的设备等待队列，而是在设备等待队列醒来时调用一个回调函数（当然，这就需要“唤醒回调”机制），把产生事件的fd归入一个链表，然后返回这个链表上的fd。另外，epoll机制实现了自己特有的文件系统eventpoll filesystem。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Unix/Linux 中的五种 I/O 模型</title>
      <link>https://jacktang816.github.io/post/iomodel/</link>
      <pubDate>Wed, 12 Jun 2019 21:27:12 +0800</pubDate>
      
      <guid>https://jacktang816.github.io/post/iomodel/</guid>
      <description>&lt;p&gt;IO模型的选择在Linux网络编程中十分重要，在Unix/Linux环境中主要提供了五种不同的IO模型，分别是阻塞式IO、非阻塞式IO、IO多路复用、信号驱动式IO和异步IO。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>